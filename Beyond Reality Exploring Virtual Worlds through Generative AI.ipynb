{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":21695,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building a Convolutional Neural Network CNN using Estimators from TensorFlow Docs\n\nThe `tf.layers` module provides a high-level API that makes\nit easy to construct a neural network. It provides methods that facilitate the\ncreation of dense (fully connected) layers and convolutional layers, adding\nactivation functions, and applying dropout regularization. In this tutorial,\nyou'll learn how to use `layers` to build a convolutional neural network model\nto recognize the handwritten digits in the MNIST data set.\n\n![handwritten digits 0–9 from the MNIST data set](https://www.tensorflow.org/images/mnist_0-9.png)\n\nThe [MNIST dataset](http://yann.lecun.com/exdb/mnist/) comprises 60,000\ntraining examples and 10,000 test examples of the handwritten digits 0–9,\nformatted as 28x28-pixel monochrome images.\n\n## Get Started\n\nLet's set up the imports for our TensorFlow program:","metadata":{"_uuid":"8c35b8d0a2347d3148c3fd2b23558bd620a04993"}},{"cell_type":"code","source":"from __future__ import absolute_import, division, print_function\n\nimport tensorflow as tf\nimport numpy as np\n\ntf.logging.set_verbosity(tf.logging.INFO)","metadata":{"_uuid":"49b94f044fb269ead3100d966003206c3bc4b200","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you work through the tutorial, you'll add code to construct, train, and\nevaluate the convolutional neural network. The complete, final code can be\n[found here](https://www.tensorflow.org/code/tensorflow/examples/tutorials/layers/cnn_mnist.py).\n\n## Intro to Convolutional Neural Networks\n\nConvolutional neural networks (CNNs) are the current state-of-the-art model\narchitecture for image classification tasks. CNNs apply a series of filters to\nthe raw pixel data of an image to extract and learn higher-level features, which\nthe model can then use for classification. CNNs contains three components:\n\n*   **Convolutional layers**, which apply a specified number of convolution\n    filters to the image. For each subregion, the layer performs a set of\n    mathematical operations to produce a single value in the output feature map.\n    Convolutional layers then typically apply a\n    [ReLU activation function](https://en.wikipedia.org/wiki/Rectifier_\\(neural_networks\\)) to\n    the output to introduce nonlinearities into the model.\n\n*   **Pooling layers**, which\n    [downsample the image data](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer)\n    extracted by the convolutional layers to reduce the dimensionality of the\n    feature map in order to decrease processing time. A commonly used pooling\n    algorithm is max pooling, which extracts subregions of the feature map\n    (e.g., 2x2-pixel tiles), keeps their maximum value, and discards all other\n    values.\n\n*   **Dense (fully connected) layers**, which perform classification on the\n    features extracted by the convolutional layers and downsampled by the\n    pooling layers. In a dense layer, every node in the layer is connected to\n    every node in the preceding layer.\n\nTypically, a CNN is composed of a stack of convolutional modules that perform\nfeature extraction. Each module consists of a convolutional layer followed by a\npooling layer. The last convolutional module is followed by one or more dense\nlayers that perform classification. The final dense layer in a CNN contains a\nsingle node for each target class in the model (all the possible classes the\nmodel may predict), with a\n[softmax](https://en.wikipedia.org/wiki/Softmax_function) activation function to\ngenerate a value between 0–1 for each node (the sum of all these softmax values\nis equal to 1). We can interpret the softmax values for a given image as\nrelative measurements of how likely it is that the image falls into each target\nclass.\n\nNote: For a more comprehensive walkthrough of CNN architecture, see Stanford University's [Convolutional Neural Networks for Visual Recognition course material](https://cs231n.github.io/convolutional-networks/).","metadata":{"_uuid":"d9d3ba3f7c40710a993acd205e713fde72d777c0"}},{"cell_type":"markdown","source":"## Building the CNN MNIST Classifier\n\nLet's build a model to classify the images in the MNIST dataset using the\nfollowing CNN architecture:\n\n1.  **Convolutional Layer #1**: Applies 32 5x5 filters (extracting 5x5-pixel\n    subregions), with ReLU activation function\n2.  **Pooling Layer #1**: Performs max pooling with a 2x2 filter and stride of 2\n    (which specifies that pooled regions do not overlap)\n3.  **Convolutional Layer #2**: Applies 64 5x5 filters, with ReLU activation\n    function\n4.  **Pooling Layer #2**: Again, performs max pooling with a 2x2 filter and\n    stride of 2\n5.  **Dense Layer #1**: 1,024 neurons, with dropout regularization rate of 0.4\n    (probability of 0.4 that any given element will be dropped during training)\n6.  **Dense Layer #2 (Logits Layer)**: 10 neurons, one for each digit target\n    class (0–9).\n\nThe `tf.layers` module contains methods to create each of the three layer types\nabove:\n\n*   `conv2d()`. Constructs a two-dimensional convolutional layer. Takes number\n    of filters, filter kernel size, padding, and activation function as\n    arguments.\n*   `max_pooling2d()`. Constructs a two-dimensional pooling layer using the\n    max-pooling algorithm. Takes pooling filter size and stride as arguments.\n*   `dense()`. Constructs a dense layer. Takes number of neurons and activation\n    function as arguments.\n\nEach of these methods accepts a tensor as input and returns a transformed tensor\nas output. This makes it easy to connect one layer to another: just take the\noutput from one layer-creation method and supply it as input to another.\n\nAdd the following `cnn_model_fn` function, which\nconforms to the interface expected by TensorFlow's Estimator API (more on this\nlater in [Create the Estimator](#create-the-estimator)). This function takes\nMNIST feature data, labels, and mode (from\n`tf.estimator.ModeKeys`: `TRAIN`, `EVAL`, `PREDICT`) as arguments;\nconfigures the CNN; and returns predictions, loss, and a training operation:","metadata":{"_uuid":"84704da3b45de302d73e09ac3e2192a7e81947b6"}},{"cell_type":"code","source":"def cnn_model_fn(features, labels, mode):\n  \"\"\"Model function for CNN.\"\"\"\n  # Input Layer\n  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n\n  # Convolutional Layer #1\n  conv1 = tf.layers.conv2d(\n      inputs=input_layer,\n      filters=32,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n\n  # Pooling Layer #1\n  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n  # Convolutional Layer #2 and Pooling Layer #2\n  conv2 = tf.layers.conv2d(\n      inputs=pool1,\n      filters=64,\n      kernel_size=[5, 5],\n      padding=\"same\",\n      activation=tf.nn.relu)\n  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n  # Dense Layer\n  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n  dropout = tf.layers.dropout(\n      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n\n  # Logits Layer\n  logits = tf.layers.dense(inputs=dropout, units=10)\n\n  predictions = {\n      # Generate predictions (for PREDICT and EVAL mode)\n      \"classes\": tf.argmax(input=logits, axis=1),\n      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n      # `logging_hook`.\n      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n  }\n\n  if mode == tf.estimator.ModeKeys.PREDICT:\n    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n  # Calculate Loss (for both TRAIN and EVAL modes)\n  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n\n  # Configure the Training Op (for TRAIN mode)\n  if mode == tf.estimator.ModeKeys.TRAIN:\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n    train_op = optimizer.minimize(\n        loss=loss,\n        global_step=tf.train.get_global_step())\n    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n  # Add evaluation metrics (for EVAL mode)\n  eval_metric_ops = {\n      \"accuracy\": tf.metrics.accuracy(\n          labels=labels, predictions=predictions[\"classes\"])\n  }\n  return tf.estimator.EstimatorSpec(\n      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)","metadata":{"_uuid":"de854afaec2c998c3a8f0a02050bede2aac55869","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following sections (with headings corresponding to each code block above)\ndive deeper into the `tf.layers` code used to create each layer, as well as how\nto calculate loss, configure the training op, and generate predictions. If\nyou're already experienced with CNNs and [TensorFlow `Estimator`s](../../guide/custom_estimators.md),\nand find the above code intuitive, you may want to skim these sections or just\nskip ahead to [\"Training and Evaluating the CNN MNIST Classifier\"](#train_eval_mnist).\n\n### Input Layer\n\nThe methods in the `layers` module for creating convolutional and pooling layers\nfor two-dimensional image data expect input tensors to have a shape of\n<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n<em>channels</em>]</code> by default. This behavior can be changed using the\n<code><em>data_format</em></code> parameter; defined as follows:\n\n*   `batch_size` —Size of the subset of examples to use when performing\n    gradient descent during training.\n*   `image_height` —Height of the example images.\n*   `image_width` —Width of the example images.\n*   `channels` —Number of color channels in the example images. For color\n    images, the number of channels is 3 (red, green, blue). For monochrome\n    images, there is just 1 channel (black).\n*   `data_format` —A string, one of `channels_last` (default) or `channels_first`.\n      `channels_last` corresponds to inputs with shape\n      `(batch, ..., channels)` while `channels_first` corresponds to\n      inputs with shape `(batch, channels, ...)`.\n\nHere, our MNIST dataset is composed of monochrome 28x28 pixel images, so the\ndesired shape for our input layer is <code>[<em>batch_size</em>, 28, 28,\n1]</code>.\n\nTo convert our input feature map (`features`) to this shape, we can perform the\nfollowing `reshape` operation:\n\n```\ninput_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n```\n\nNote that we've indicated `-1` for batch size, which specifies that this\ndimension should be dynamically computed based on the number of input values in\n`features[\"x\"]`, holding the size of all other dimensions constant. This allows\nus to treat `batch_size` as a hyperparameter that we can tune. For example, if\nwe feed examples into our model in batches of 5, `features[\"x\"]` will contain\n3,920 values (one value for each pixel in each image), and `input_layer` will\nhave a shape of `[5, 28, 28, 1]`. Similarly, if we feed examples in batches of\n100, `features[\"x\"]` will contain 78,400 values, and `input_layer` will have a\nshape of `[100, 28, 28, 1]`.\n\n### Convolutional Layer #1\n\nIn our first convolutional layer, we want to apply 32 5x5 filters to the input\nlayer, with a ReLU activation function. We can use the `conv2d()` method in the\n`layers` module to create this layer as follows:\n\n```\nconv1 = tf.layers.conv2d(\n    inputs=input_layer,\n    filters=32,\n    kernel_size=[5, 5],\n    padding=\"same\",\n    activation=tf.nn.relu)\n```\n\nThe `inputs` argument specifies our input tensor, which must have the shape\n<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n<em>channels</em>]</code>. Here, we're connecting our first convolutional layer\nto `input_layer`, which has the shape <code>[<em>batch_size</em>, 28, 28,\n1]</code>.\n\nNote: `conv2d()` will instead accept a shape of `[<em>batch_size</em>, <em>channels</em>, <em>image_height</em>, <em>image_width</em>]` when passed the argument `data_format=channels_first`.\n\nThe `filters` argument specifies the number of filters to apply (here, 32), and\n`kernel_size` specifies the dimensions of the filters as `[<em>height</em>,\n<em>width</em>]</code> (here, <code>[5, 5]`).\n\n<p class=\"tip\"><b>TIP:</b> If filter height and width have the same value, you can instead specify a\nsingle integer for <code>kernel_size</code>—e.g., <code>kernel_size=5</code>.</p>\n\nThe `padding` argument specifies one of two enumerated values\n(case-insensitive): `valid` (default value) or `same`. To specify that the\noutput tensor should have the same height and width values as the input tensor,\nwe set `padding=same` here, which instructs TensorFlow to add 0 values to the\nedges of the input tensor to preserve height and width of 28. (Without padding,\na 5x5 convolution over a 28x28 tensor will produce a 24x24 tensor, as there are\n24x24 locations to extract a 5x5 tile from a 28x28 grid.)\n\nThe `activation` argument specifies the activation function to apply to the\noutput of the convolution. Here, we specify ReLU activation with\n`tf.nn.relu`.\n\nOur output tensor produced by `conv2d()` has a shape of\n<code>[<em>batch_size</em>, 28, 28, 32]</code>: the same height and width\ndimensions as the input, but now with 32 channels holding the output from each\nof the filters.","metadata":{"_uuid":"6e49f9c0d7dc496de398f940898911d033a2b26d"}},{"cell_type":"markdown","source":"### Pooling Layer #1\n\nNext, we connect our first pooling layer to the convolutional layer we just\ncreated. We can use the `max_pooling2d()` method in `layers` to construct a\nlayer that performs max pooling with a 2x2 filter and stride of 2:\n\n```\npool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n```\n\nAgain, `inputs` specifies the input tensor, with a shape of\n<code>[<em>batch_size</em>, <em>image_height</em>, <em>image_width</em>,\n<em>channels</em>]</code>. Here, our input tensor is `conv1`, the output from\nthe first convolutional layer, which has a shape of <code>[<em>batch_size</em>,\n28, 28, 32]</code>.\n\nNote: As with <code>conv2d()</code>, <code>max_pooling2d()</code> will instead\naccept a shape of <code>[<em>batch_size</em>, <em>channels</em>, \n<em>image_height</em>, <em>image_width</em>]</code> when passed the argument\n<code>data_format=channels_first</code>.\n\nThe `pool_size` argument specifies the size of the max pooling filter as\n<code>[<em>height</em>, <em>width</em>]</code> (here, `[2, 2]`). If both\ndimensions have the same value, you can instead specify a single integer (e.g.,\n`pool_size=2`).\n\nThe `strides` argument specifies the size of the stride. Here, we set a stride\nof 2, which indicates that the subregions extracted by the filter should be\nseparated by 2 pixels in both the height and width dimensions (for a 2x2 filter,\nthis means that none of the regions extracted will overlap). If you want to set\ndifferent stride values for height and width, you can instead specify a tuple or\nlist (e.g., `stride=[3, 6]`).\n\nOur output tensor produced by `max_pooling2d()` (`pool1`) has a shape of\n<code>[<em>batch_size</em>, 14, 14, 32]</code>: the 2x2 filter reduces height and width by 50% each.","metadata":{"_uuid":"43acd27e0ec83b055a0395aa89446c942f7151ef"}},{"cell_type":"markdown","source":"### Convolutional Layer #2 and Pooling Layer #2\n\nWe can connect a second convolutional and pooling layer to our CNN using\n`conv2d()` and `max_pooling2d()` as before. For convolutional layer #2, we\nconfigure 64 5x5 filters with ReLU activation, and for pooling layer #2, we use\nthe same specs as pooling layer #1 (a 2x2 max pooling filter with stride of 2):\n\n```\nconv2 = tf.layers.conv2d(\n    inputs=pool1,\n    filters=64,\n    kernel_size=[5, 5],\n    padding=\"same\",\n    activation=tf.nn.relu)\n\npool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n```\n\nNote that convolutional layer #2 takes the output tensor of our first pooling\nlayer (`pool1`) as input, and produces the tensor `conv2` as output. `conv2`\nhas a shape of <code>[<em>batch_size</em>, 14, 14, 64]</code>, the same height and width as `pool1` (due to `padding=\"same\"`), and 64 channels for the 64\nfilters applied.\n\nPooling layer #2 takes `conv2` as input, producing `pool2` as output. `pool2`\nhas shape <code>[<em>batch_size</em>, 7, 7, 64]</code> (50% reduction of height and width from `conv2`).","metadata":{"_uuid":"14e082169eee305d533809181d7b81375197f3c2"}},{"cell_type":"markdown","source":"### Dense Layer\n\nNext, we want to add a dense layer (with 1,024 neurons and ReLU activation) to\nour CNN to perform classification on the features extracted by the\nconvolution/pooling layers. Before we connect the layer, however, we'll flatten\nour feature map (`pool2`) to shape <code>[<em>batch_size</em>,\n<em>features</em>]</code>, so that our tensor has only two dimensions:\n\n```\npool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n```\n\nIn the `reshape()` operation above, the `-1` signifies that the *`batch_size`*\ndimension will be dynamically calculated based on the number of examples in our\ninput data. Each example has 7 (`pool2` height) * 7 (`pool2` width) * 64\n(`pool2` channels) features, so we want the `features` dimension to have a value\nof 7 * 7 * 64 (3136 in total). The output tensor, `pool2_flat`, has shape\n<code>[<em>batch_size</em>, 3136]</code>.\n\nNow, we can use the `dense()` method in `layers` to connect our dense layer as\nfollows:\n\n```\ndense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n```\n\nThe `inputs` argument specifies the input tensor: our flattened feature map,\n`pool2_flat`. The `units` argument specifies the number of neurons in the dense\nlayer (1,024). The `activation` argument takes the activation function; again,\nwe'll use `tf.nn.relu` to add ReLU activation.\n\nTo help improve the results of our model, we also apply dropout regularization\nto our dense layer, using the `dropout` method in `layers`:\n\n```\ndropout = tf.layers.dropout(\n    inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n```\n\nAgain, `inputs` specifies the input tensor, which is the output tensor from our\ndense layer (`dense`).\n\nThe `rate` argument specifies the dropout rate; here, we use `0.4`, which means\n40% of the elements will be randomly dropped out during training.\n\nThe `training` argument takes a boolean specifying whether or not the model is\ncurrently being run in training mode; dropout will only be performed if\n`training` is `True`. Here, we check if the `mode` passed to our model function\n`cnn_model_fn` is `TRAIN` mode.\n\nOur output tensor `dropout` has shape <code>[<em>batch_size</em>, 1024]</code>.","metadata":{"_uuid":"3090622c0a72d5858e4a2adc2a103f9b9dbaebec"}},{"cell_type":"markdown","source":"### Logits Layer\n\nThe final layer in our neural network is the logits layer, which will return the\nraw values for our predictions. We create a dense layer with 10 neurons (one for\neach target class 0–9), with linear activation (the default):\n\n```\nlogits = tf.layers.dense(inputs=dropout, units=10)\n```\n\nOur final output tensor of the CNN, `logits`, has shape `[batch_size, 10]`.","metadata":{"_uuid":"615daa1eb0b5f98158cc66b43f60321cf67fdd41"}},{"cell_type":"markdown","source":"### Generate Predictions {#generate_predictions}\n\nThe logits layer of our model returns our predictions as raw values in a\n<code>[<em>batch_size</em>, 10]</code>-dimensional tensor. Let's convert these\nraw values into two different formats that our model function can return:\n\n*   The **predicted class** for each example: a digit from 0–9.\n*   The **probabilities** for each possible target class for each example: the\n    probability that the example is a 0, is a 1, is a 2, etc.\n\nFor a given example, our predicted class is the element in the corresponding row\nof the logits tensor with the highest raw value. We can find the index of this\nelement using the `tf.argmax`\nfunction:\n\n```\ntf.argmax(input=logits, axis=1)\n```\n\nThe `input` argument specifies the tensor from which to extract maximum\nvalues—here `logits`. The `axis` argument specifies the axis of the `input`\ntensor along which to find the greatest value. Here, we want to find the largest\nvalue along the dimension with index of 1, which corresponds to our predictions\n(recall that our logits tensor has shape <code>[<em>batch_size</em>,\n10]</code>).\n\nWe can derive probabilities from our logits layer by applying softmax activation\nusing `tf.nn.softmax`:\n\n```\ntf.nn.softmax(logits, name=\"softmax_tensor\")\n```\n\nNote: We use the `name` argument to explicitly name this operation `softmax_tensor`, so we can reference it later. (We'll set up logging for the softmax values in [\"Set Up a Logging Hook\"](#set-up-a-logging-hook)).\n\nWe compile our predictions in a dict, and return an `EstimatorSpec` object:\n\n```\npredictions = {\n    \"classes\": tf.argmax(input=logits, axis=1),\n    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n}\nif mode == tf.estimator.ModeKeys.PREDICT:\n  return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n```","metadata":{"_uuid":"417b3cf0d61f79334bb52bca9736cc1798ddb5b7"}},{"cell_type":"markdown","source":"### Calculate Loss {#calculating-loss}\n\nFor both training and evaluation, we need to define a\n[loss function](https://en.wikipedia.org/wiki/Loss_function)\nthat measures how closely the model's predictions match the target classes. For\nmulticlass classification problems like MNIST,\n[cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) is typically used\nas the loss metric. The following code calculates cross entropy when the model\nruns in either `TRAIN` or `EVAL` mode:\n\n```\nloss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n```\n\nLet's take a closer look at what's happening above.\n\nOur `labels` tensor contains a list of prediction indices for our examples, e.g. `[1,\n9, ...]`. `logits` contains the linear outputs of our last layer. \n\n`tf.losses.sparse_softmax_cross_entropy`, calculates the softmax crossentropy\n(aka: categorical crossentropy, negative log-likelihood) from these two inputs\nin an efficient, numerically stable way.","metadata":{"_uuid":"5495dde88ab5f50c4ddf971120c8659dda2b441f"}},{"cell_type":"markdown","source":"### Configure the Training Op\n\nIn the previous section, we defined loss for our CNN as the softmax\ncross-entropy of the logits layer and our labels. Let's configure our model to\noptimize this loss value during training. We'll use a learning rate of 0.001 and\n[stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\nas the optimization algorithm:\n\n```\nif mode == tf.estimator.ModeKeys.TRAIN:\n  optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n  train_op = optimizer.minimize(\n      loss=loss,\n      global_step=tf.train.get_global_step())\n  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n```","metadata":{"_uuid":"05b38836e1ecf819620c2b4ef4a57201d0e17d76"}},{"cell_type":"markdown","source":"### Add evaluation metrics\n\nTo add accuracy metric in our model, we define `eval_metric_ops` dict in EVAL\nmode as follows:\n\n```\neval_metric_ops = {\n    \"accuracy\": tf.metrics.accuracy(\n        labels=labels, predictions=predictions[\"classes\"])\n}\nreturn tf.estimator.EstimatorSpec(\n    mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n```","metadata":{"_uuid":"7216fe51880596bdfe9d2475d7ff8bcb22caa613"}},{"cell_type":"markdown","source":"<a id=\"train_eval_mnist\"></a>\n## Training and Evaluating the CNN MNIST Classifier\n\nWe've coded our MNIST CNN model function; now we're ready to train and evaluate\nit.\n\n### Load Training and Test Data\n\nFirst, let's load our training and test data with the following code:","metadata":{"_uuid":"d5d8a29662767394ef20bc50eb85af211e3a51f0"}},{"cell_type":"code","source":"# Load training and eval data\n((train_data, train_labels),\n (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n\ntrain_data = train_data/np.float32(255)\ntrain_labels = train_labels.astype(np.int32)  # not required\n\neval_data = eval_data/np.float32(255)\neval_labels = eval_labels.astype(np.int32)  # not required","metadata":{"_uuid":"befd62f26d3db4ff1c50fa04e9e65d703d16a518","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We store the training feature data (the raw pixel values for 55,000 images of\nhand-drawn digits) and training labels (the corresponding value from 0–9 for\neach image) as [numpy\narrays](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html)\nin `train_data` and `train_labels`, respectively. Similarly, we store the\nevaluation feature data (10,000 images) and evaluation labels in `eval_data`\nand `eval_labels`, respectively\n\n### Create the Estimator {#create-the-estimator}\n\nNext, let's create an `Estimator` (a TensorFlow class for performing high-level\nmodel training, evaluation, and inference) for our model. Add the following code\nto `main()`:","metadata":{"_uuid":"25335bd223a697ab3a183d074f4853889f8db71d"}},{"cell_type":"code","source":"# Create the Estimator\nmnist_classifier = tf.estimator.Estimator(\n    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")","metadata":{"_uuid":"8e398c758ac9dd24c1a1a764313a92e09e6e2a57","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `model_fn` argument specifies the model function to use for training,\nevaluation, and prediction; we pass it the `cnn_model_fn` we created in\n[\"Building the CNN MNIST Classifier.\"](#building-the-cnn-mnist-classifier) The\n`model_dir` argument specifies the directory where model data (checkpoints) will\nbe saved (here, we specify the temp directory `/tmp/mnist_convnet_model`, but\nfeel free to change to another directory of your choice).\n\nNote: For an in-depth walkthrough of the TensorFlow `Estimator` API, see the tutorial [Creating Estimators in tf.estimator](../../guide/custom_estimators.md).","metadata":{"_uuid":"af225e8b4d1b0314f9d150ddc516949fe4351468"}},{"cell_type":"markdown","source":"### Set Up a Logging Hook {#set_up_a_logging_hook}\n\nSince CNNs can take a while to train, let's set up some logging so we can track\nprogress during training. We can use TensorFlow's `tf.train.SessionRunHook` to create a\n`tf.train.LoggingTensorHook`\nthat will log the probability values from the softmax layer of our CNN. Add the\nfollowing to `main()`:","metadata":{"_uuid":"a57865907bd73a7e05a65c2c0fa2ef001e9f32ae"}},{"cell_type":"code","source":"# Set up logging for predictions\ntensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n\nlogging_hook = tf.train.LoggingTensorHook(\n    tensors=tensors_to_log, every_n_iter=50)","metadata":{"_uuid":"8f0789f87aed15da79091d3b6136bac5e1275dc3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We store a dict of the tensors we want to log in `tensors_to_log`. Each key is a\nlabel of our choice that will be printed in the log output, and the\ncorresponding label is the name of a `Tensor` in the TensorFlow graph. Here, our\n`probabilities` can be found in `softmax_tensor`, the name we gave our softmax\noperation earlier when we generated the probabilities in `cnn_model_fn`.\n\nNote: If you don't explicitly assign a name to an operation via the `name` argument, TensorFlow will assign a default name. A couple easy ways to discover the names applied to operations are to visualize your graph on [TensorBoard](../../guide/graph_viz.md)) or to enable the [TensorFlow Debugger (tfdbg)](../../guide/debugger.md).\n\nNext, we create the `LoggingTensorHook`, passing `tensors_to_log` to the\n`tensors` argument. We set `every_n_iter=50`, which specifies that probabilities\nshould be logged after every 50 steps of training.\n\n### Train the Model\n\nNow we're ready to train our model, which we can do by creating `train_input_fn`\nand calling `train()` on `mnist_classifier`. In the `numpy_input_fn` call, we pass the training feature data and labels to\n`x` (as a dict) and `y`, respectively. We set a `batch_size` of `100` (which\nmeans that the model will train on minibatches of 100 examples at each step).\n`num_epochs=None` means that the model will train until the specified number of\nsteps is reached. We also set `shuffle=True` to shuffle the training data. Then train the model a single step and log the output:","metadata":{"_uuid":"02e63477de9d5b2681fbb39047ebb28126f1ccee"}},{"cell_type":"code","source":"# Train the model\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"x\": train_data},\n    y=train_labels,\n    batch_size=100,\n    num_epochs=None,\n    shuffle=True)\n\n# train one step and display the probabilties\nmnist_classifier.train(\n    input_fn=train_input_fn,\n    steps=1,\n    hooks=[logging_hook])","metadata":{"_uuid":"13e16c82c698d1a209fdac5c8f2c2fe8b3f26b74","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now—without logging each step—set `steps=1000` to train the model longer, but in a reasonable time to run this example. Training CNNs is computationally intensive. To increase the accuracy of your model, increase the number of `steps` passed to `train()`, like 20,000 steps. ","metadata":{"_uuid":"b7819e18bbc2af228bcfdab9f5f6e0d764e1b921"}},{"cell_type":"code","source":"mnist_classifier.train(input_fn=train_input_fn, steps=1000)","metadata":{"_uuid":"c2673de4a2cceced373049a64b6822b078da3260","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Evaluate the Model\n\nOnce training is complete, we want to evaluate our model to determine its\naccuracy on the MNIST test set. We call the `evaluate` method, which evaluates\nthe metrics we specified in `eval_metric_ops` argument in the `model_fn`.\nAdd the following to `main()`:","metadata":{"_uuid":"38cd2a5baef08bae7f0742e679851bb9c3b5b17f"}},{"cell_type":"code","source":"eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={\"x\": eval_data},\n    y=eval_labels,\n    num_epochs=1,\n    shuffle=False)\n\neval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\nprint(eval_results)","metadata":{"_uuid":"4f1aac70ced7d3cdb36bf9a8897cd3e6d63c0b29","trusted":true},"execution_count":null,"outputs":[]}]}